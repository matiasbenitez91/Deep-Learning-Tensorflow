{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda2\\envs\\translator\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense\n",
    "from keras.layers import TimeDistributed, Dropout, Bidirectional\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "# Maximum length of text sentences\n",
    "MAXLEN = 180\n",
    "# Number of LSTM units\n",
    "LSTM_N = 150\n",
    "# batch size\n",
    "BS=48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"ner_dataset.csv\", encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of uniques docs, sentences and words in Training set:\n",
      " Sentence #    47959\n",
      "Word          35178\n",
      "POS              42\n",
      "Tag              17\n",
      "dtype: int64\n",
      "\n",
      "Length of vocabulary =  35179\n",
      "\n",
      "number of tags =  17\n"
     ]
    }
   ],
   "source": [
    "# Creating a vocabulary\n",
    "print(\"Number of uniques docs, sentences and words in Training set:\\n\",data.nunique())\n",
    "\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    " \n",
    "# Converting greek characters to ASCII characters eg. 'naïve café' to 'naive cafe'\n",
    "words = [unicodedata.normalize('NFKD', str(w)).encode('ascii','ignore') for w in words]\n",
    "n_words = len(words)\n",
    "\n",
    "\n",
    "print(\"\\nLength of vocabulary = \",n_words)\n",
    " \n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags)\n",
    "print(\"\\nnumber of tags = \",n_tags)\n",
    " \n",
    "# Creating words to indices dictionary.\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "# Creating tags to indices dictionary.\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['Sentence #'][1])==float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "list_=[]\n",
    "for sent in data['Sentence #']:\n",
    "    if type(sent)!=float:\n",
    "        counter+=1\n",
    "    list_.append(counter)\n",
    "data['Sent_ID']=list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tresh=data.index[data['Sentence #'] == \"Sentence: \"+str(round(47959*0.80))][0]\n",
    "test_data=data.iloc[split_tresh:,:]\n",
    "train_data=data.iloc[:split_tresh,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 sentences in a word list format:\n",
      " [[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')], [('Families', 'O'), ('of', 'O'), ('soldiers', 'O'), ('killed', 'O'), ('in', 'O'), ('the', 'O'), ('conflict', 'O'), ('joined', 'O'), ('the', 'O'), ('protesters', 'O'), ('who', 'O'), ('carried', 'O'), ('banners', 'O'), ('with', 'O'), ('such', 'O'), ('slogans', 'O'), ('as', 'O'), ('\"', 'O'), ('Bush', 'B-per'), ('Number', 'O'), ('One', 'O'), ('Terrorist', 'O'), ('\"', 'O'), ('and', 'O'), ('\"', 'O'), ('Stop', 'O'), ('the', 'O'), ('Bombings', 'O'), ('.', 'O'), ('\"', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "def get_tagged_sentences(data):\n",
    "    agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
    "    grouped = data.groupby(\"Sent_ID\").apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    return sentences\n",
    " \n",
    "def get_test_sentences(data):\n",
    "    agg_func = lambda s: [w for w in s[\"Word\"].values.tolist()]\n",
    "    grouped = data.groupby(\"Sent\").apply(agg_func)\n",
    "    sentences = [s for s in grouped]\n",
    "    return sentences\n",
    "# Getting training sentences in a list\n",
    "sentences = get_tagged_sentences(train_data)\n",
    "test_sentences = get_tagged_sentences(test_data)\n",
    "print(\"First 2 sentences in a word list format:\\n\",sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[unicodedata.normalize('NFKD', str(w[0])).\n",
    "encode('ascii','ignore')] for w in s] for s in sentences]\n",
    " \n",
    "# Converting words to indices for test sentences (Features)\n",
    "# Converting greek characters to ASCII characters in test-set eg. 'naïve café' to 'naive cafe'\n",
    "X_test = [[word2idx[unicodedata.normalize('NFKD', str(w[0])).\n",
    "encode('ascii','ignore')] for w in s] for s in test_sentences]\n",
    "\n",
    "X = keras.preprocessing.sequence.pad_sequences(maxlen=MAXLEN, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(maxlen=MAXLEN, sequences=X_test, padding=\"post\", value=n_words - 1)\n",
    " \n",
    "# Converting tags to indices for test sentences (labels)\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "# Padding tag labels to 180 words.\n",
    "y = keras.preprocessing.sequence.pad_sequences(maxlen=MAXLEN, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    " \n",
    "# Making labels in one hot encoded form for DL model\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36447 samples, validate on 1919 samples\n",
      "Epoch 1/2\n",
      "36447/36447 [==============================] - 1188s 33ms/step - loss: 0.0740 - acc: 0.9860 - val_loss: 0.0209 - val_acc: 0.9942\n",
      "Epoch 2/2\n",
      "36447/36447 [==============================] - 1204s 33ms/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.0151 - val_acc: 0.9954\n"
     ]
    }
   ],
   "source": [
    "# 180 dimensional word indices as input\n",
    "input = Input(shape=(MAXLEN,))\n",
    " \n",
    "# Embedding layer of same length output (180 dim embedding will be generated)\n",
    "model = Embedding(input_dim=n_words, output_dim=MAXLEN, input_length=MAXLEN)(input)\n",
    " \n",
    "# Adding dropout layer\n",
    "model = Dropout(0.2)(model)\n",
    " \n",
    "# Bidirectional LSTM to learn from both forward as well as backward context\n",
    "model = Bidirectional(LSTM(units=LSTM_N, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    " \n",
    "# Adding a TimeDistributedDense, to applying a Dense layer on each 180 timesteps\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model) # softmax output layer\n",
    "model = Model(input, out)\n",
    " \n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history = model.fit(X, np.array(y), batch_size=BS, epochs=2, validation_split=0.05, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = np.argmax(t, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids,tagids = X_test.flatten().tolist(), pred_index.flatten().tolist()\n",
    "\n",
    "words_test = [words[ind].decode('utf-8') for ind in ids]\n",
    "# converting each predicted tag indices back to tags\n",
    "tags_test = [tags[ind] for ind in tagids]\n",
    "\n",
    "true_index = np.argmax(y, axis=-1)\n",
    "pred=true_index.flatten().tolist()\n",
    "true_tags= [tags[ind] for ind in pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= [[tag2idx[w[1]] for w in s] for s in test_sentences]\n",
    "# Padding tag labels to 180 words.\n",
    "y_test = keras.preprocessing.sequence.pad_sequences(maxlen=MAXLEN, sequences=y_test, padding=\"post\", value=tag2idx[\"O\"])\n",
    " \n",
    "# Making labels in one hot encoded form for DL model\n",
    "y_test = [to_categorical(i, num_classes=n_tags) for i in y_test]\n",
    "          \n",
    "          \n",
    "true_index = np.argmax(y_test, axis=-1)\n",
    "pred=true_index.flatten().tolist()\n",
    "true_tags= [tags[ind] for ind in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'word':words_test,\"True_tag\":true_tags,\"pred_tags\":tags_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>True_tag</th>\n",
       "      <th>pred_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr.</td>\n",
       "      <td>B-per</td>\n",
       "      <td>B-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nour</td>\n",
       "      <td>I-per</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arrested</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>January</td>\n",
       "      <td>B-tim</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>I-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>six</td>\n",
       "      <td>B-tim</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weeks</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jail</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>before</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>his</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>release</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bond</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word True_tag pred_tags\n",
       "0        Mr.    B-per     B-per\n",
       "1       Nour    I-per     I-per\n",
       "2        was        O         O\n",
       "3   arrested        O         O\n",
       "4         in        O         O\n",
       "5    January    B-tim     B-tim\n",
       "6        and        O     I-tim\n",
       "7      spent        O         O\n",
       "8        six    B-tim     B-tim\n",
       "9      weeks        O         O\n",
       "10        in        O         O\n",
       "11         a        O         O\n",
       "12     Cairo    B-geo     B-geo\n",
       "13      jail        O         O\n",
       "14         ,        O         O\n",
       "15    before        O         O\n",
       "16       his        O         O\n",
       "17   release        O         O\n",
       "18        on        O         O\n",
       "19      bond        O         O"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 180, 180)          6332220   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 180, 180)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 180, 300)          397200    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 180, 17)           5117      \n",
      "=================================================================\n",
      "Total params: 6,734,537\n",
      "Trainable params: 6,734,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
